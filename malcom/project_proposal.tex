\documentclass{article}
\usepackage[margin=1.2in]{geometry} % change this parameter to enlarge/restrict the margins
\usepackage{amsmath,amsthm,amssymb,amsfonts, fancyhdr, color, comment, graphicx, environ}
\usepackage{xcolor}
\usepackage{mdframed}
\usepackage[shortlabels]{enumitem}
\usepackage{hyperref}
\usepackage{calrsfs}
\DeclareMathAlphabet{\pazocal}{OMS}{zplm}{m}{n}
\usepackage{graphicx}

\renewcommand{\footrulewidth}{0.8pt}
\hypersetup{
	colorlinks=true,
	linkcolor=blue,
	filecolor=magenta,      
	urlcolor=blue,
}

% fancy style 
\pagestyle{fancy}
% remove fancy style from bottom 
\renewcommand{\footrulewidth}{0pt}

\lhead{Gabriele Gioetto, Simone Papicchio, Massimiliano Pronesti}
\rhead{MALCOM} 

\newcommand{\loss}{L(\theta, a)}
\newcommand{\lossRule}{L(\theta, \delta(x))}
\newcommand{\risk}{R(\theta, \delta)}

%------------------------------------------------
%% Bibliography
\usepackage[sorting=none, backend=bibtex]{biblatex}
\addbibresource{ref.bib}
%------------------------------------------------


\begin{document}
	\input{coverPage}
	
\section{Project Description}

Nowadays, a lot of data is generated but cannot be exploited due to its sensitive nature. For
instance, we can think of the data collected by the cameras or GPS sensors in our mobile phones,
or the performed ultrasounds and X-ray scans, or the data produced by the Internet of Things
(IoT). They are all of great value to the world of Big Data and Machine Learning (ML) applications,
but they are also protected by privacy and, therefore, unusable by traditional methods.


Introduced in 2016 by Google, Federated Learning (FL) is a machine learning scenario born with
the aim of using privacy-protected data without violating the regulations in force. This framework
deals with learning a central server model in privacy-constrained scenarios, where data are
stored on multiple devices (i.e. the clients). Unlike the standard machine learning setting, here the
model has no direct access to the data, which never leave the clients’ devices: a fundamental
requirement for any application where users’ privacy must be preserved (e.g. medical records,
bank transactions).



\section{Method}
With this project, we aim to become familiar with the federated scenario and its standard architecture. Once implemented the baseline, we will analyze the variations that occur by modifying the value of the parameters specific to this framework, assessing the most effective ones. Finally, basing on the identified problems of the resulting model, we would try to propose a possible solution to address one of them. The following list represents roughly the path we want to follow:

\begin{enumerate}
    \item To get familiar with Federated Learning and its main algorithms and architecture.
    \item  To replicate the experiments proposed by \cite{DBLP:journals/corr/abs-2003-08082} on the CIFAR10 dataset.
    \item To understand the contribution made by each parameter of the federated setting by
proposing an experimental study.
\item To understand the importance of clients’ local data distribution in the federated scenario. 
\item To make our contribution for solving existing issues (Not yet defined)\\
\end{enumerate}
The idea is to start studying the first papers published by Google \cite{DBLP:journals/corr/McMahanMRA16}\cite{pmlr-v54-mcmahan17a}
where Federated Learning and its main algorithm FederatedAveraging (FedAvg) are introduced.

Then we want to replicate the experiments performed in \cite{DBLP:journals/corr/abs-2003-08082} with the CIFAR10 and CIFAR100 datasets.
In order to do so, we will implement first the baseline which is composed of:
\begin{itemize}
    \item standard updates aggregation algorithm i.e. FedAvg
    \item define the communication paradigm (synchronous vs asynchronous, number of communication
		rounds, number of clients selected at each round, etc)
	\item division of the dataset among clients.
\end{itemize}
The dataset for the Baseline will be CIFAR10. Challenging will be to understand how to adapt it to
the federated scenario, i.e. how to divide it among clients, how many clients we will have and so on. The task is image classification on 10 classes. In \cite{DBLP:journals/corr/abs-2003-08082}, there is a possible choice of the neural
network, i.e. LeNet5 \cite{726791}. We will decide whether to keep that architecture or change it.

For validating the results, the reference metric is the weighted average of the accuracy reached
by each client, where the weight corresponds to the number of samples seen by that client. 

Finally, in order to have an upper bound on the results, we will test our model in a
centralized manner, i.e. in the “standard” way, outside the federated framework (train and test the network on all data, disregarding the division among clients and the client-server architecture).

After having implemented the baseline, we will perform an experimental study. The aim of the ablation studies is to understand and verify the effects of the parameters we
blindly chose in the previous step. We expect to have variations occurring when modifying the clients’ local data distribution and the value of the FL parameters.

The last part of the project will be based on our variation. So far we spot two possible candidates:

\begin{itemize}
    \item \textbf{Algorithm for aggregating the updates on the server-side}: in FL, the standard and most
used algorithm is FederatedAveraging (FedAvg). Some works propose possible improvements and changes of FedAvg to answer different issues \cite{DBLP:journals/corr/abs-1812-06127, DBLP:journals/corr/abs-2002-07948, pmlr-v119-karimireddy20a, pmlr-v108-reisizadeh20a}.
Otherwise, different algorithms exist, such as FedSGD \cite{pmlr-v54-mcmahan17a}.
\item \textbf{Neural Network for classification}: For the classification, we will initially use LeNet5 as done in \cite{DBLP:journals/corr/abs-2003-08082}. However, we may spot different overall better model in the literature.
\end{itemize}


\section{Positioning}
Two of the main issues of Federated Learning are class imbalance and non IID data\cite{ZHANG2021106775}. 
In many real-life scenarios, the IID assumption does not hold and we could encounter class imbalance, which results in a reduction of classification accuracy on minority classes. In a Federated Learning setting, we can have trouble achieving good results in such cases.\\
Over the years different solutions have been proposed to solve such problems:
\begin{itemize}
  \item \textbf{Optimizing Federated Learning on Non-IID Data
with Reinforcement Learning}\cite{9155494}: the authors of this paper used a reinforcement-learning approach to accelerate and stabilize the federated learning process by learning to actively select the best subset of devices in each communication round that can counterbalance the bias introduced by non-IID data.
  \item \textbf{Federated Learning with Non-IID Data}\cite{DBLP:journals/corr/abs-1806-00582}: the authors introduced a trade-off between accuracy and centralization distributing a small amount of globally shared data containing examples from each class. This strategy improves \emph{FedAvg} with non-IID data
  \item \textbf{Addressing Class Imbalance in Federated Learning}\cite{DBLP:journals/corr/abs-2008-06217}: to detect the imbalance in FL timely and accurately, the authors propose to design a monitor that estimates the composition across classes during FL, and if a particular imbalanced composition appears continuously, the monitor will alert the administrator (AD) to apply measures that can mitigate the negative impact
  \item \textbf{Robust and Communication-Efficient Federated Learning From Non-i.i.d. Data}\cite{DBLP:journals/corr/abs-1903-02891}: the authors constructed a new communication protocol for federated learning that resolved different issues, among which also non IID data and imbalanced classes
\end{itemize}


\section{Plan and Intended Work}
Once the project proposal is accepted, we plan to devote the following 5 weeks to the baseline implementation as described in \textbf{Section 2}. Then, we are going to focus our attention on the Ablantion Studies for approximately 1 month. Eventually, the focus will shift on the variations, for the remaining time before the deadline.\\ 
A visual timeline describing our plan and intended work is shown in \textbf{Figure 1}.

\begin{figure}[h]
\includegraphics[width=0.9\textwidth, angle=0]{assets/timeline.pdf}
\caption{Intended timeline}
\end{figure}


\newpage
\printbibliography
\end{document}